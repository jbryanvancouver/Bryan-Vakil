%%%%%% RVpreamble.tex
%%  version April 18, 2022

% table of contents for pre-amble
% prepreamble
% margins
% picture stuff  [ready to delete]
% point commands
% fonts
% symbols
% operatornames
% editing commands


%two arrows pointing to the right:
% $\xymatrix{ A \ar@< 2pt>[r]^\phi\ar@<-2pt>[r]_\psi & B}$
%bowed arrows
%$$
%\xymatrix{U \times \R^n \ar[d]_{\pi} \\
%U\ar@/_/[u]_{f_1, \dots, f_n} 
% }$$
%$$
%\xymatrix{
%Z \ar[dr] \ar[drr]^0 \ar@{.>}[d]_{\exists !} \\  A \ar[r]^i \ar@/_1pc/[rr]_0  &
% B \ar[r]^f & C \\ 
%}$$

%\begin{figure}[ht] \begin{center}
%\includegraphics[scale=0.3]{figures/fig82.jpeg}
%\end{center} \caption{} \label{} \end{figure}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% prepreamble

\documentclass[12pt,letterpaper]{amsart} % LatexMasterTemplate May 2020 on overleaf
\usepackage{palatino, euler, epic,eepic, amssymb, xypic, floatflt, microtype}
\usepackage{verbatim,color}
\usepackage[linktocpage,hidelinks]{hyperref}



% June 9 09:  removed latexsym, amscd, and added palatino, microtype

\usepackage{tikz-cd}

\input xy
\xyoption{all}
% AK and TT say:  if your fonts are screwed up, remove the "renewcommand".
\renewcommand{\familydefault}{ppl}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% margins

% from Allen K and Terry T's notices article
\setlength{\oddsidemargin}{0cm} \setlength{\evensidemargin}{0cm}
\setlength{\marginparwidth}{0in}
\setlength{\marginparsep}{0in}
\setlength{\marginparpush}{0in}
\setlength{\topmargin}{0in}
\setlength{\headheight}{0pt}
\setlength{\headsep}{0pt}
\setlength{\footskip}{.3in}
\setlength{\textheight}{9.2in}
\setlength{\textwidth}{6.5in}
\setlength{\parskip}{4pt}

\linespread{1.15} % following Ian Morrison

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% picture stuff
 
% \newlength{\baseunit}               % the basic unit length
% \newlength{\templengthhoriz}        % width of the picture
% \newlength{\templengthvert}         % depth of the picture
% \newlength{\temprule}               % with between left margin and picture
% \newcount{\numlines}                % depth of picture (in number of lines)
% \setlength{\baseunit}{0.05ex}
  
%  \newcommand{\getfig}[2] {
%           \setlength{\unitlength}{#2\baseunit}
%            \input #1.tex }
                         % A macro to input the picture.  Use
                         % \getfig{name}{scale}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% point commands (and  theorem-related commands)


\newcommand{\bpf}{\noindent {\em Proof.  }}
\newcommand{\epf}{\qed \vspace{+10pt}}

\newcommand{\point}{\vspace{3mm}\par \noindent \refstepcounter{subsection}{\thesubsection.} }
\newcommand{\tpoint}[1]{\vspace{3mm}\par \noindent \refstepcounter{subsection}{\thesubsection.} 
  {\bf #1. ---} }
\newcommand{\epoint}[1]{\vspace{3mm}\par \noindent \refstepcounter{subsection}{\thesubsection.} 
  {\em #1.} }
\newcommand{\bpoint}[1]{\vspace{3mm}\par \noindent \refstepcounter{subsection}{\thesubsection.} 
  {\bf #1.} }

%Exercise
\newtheorem{eexercise}{Eexercise}[section]
%\newcounter{exercise}
\renewcommand{\theeexercise}{\thesection.\Alph{eexercise}}
\newcommand{\exercise}[1]{\vspace{3mm}\par\refstepcounter{eexercise}\noindent{\bf
    \theeexercise.}   {\sc #1.} }
\newcommand{\exercisedone}{ \vspace{2mm}}


% I haven't really used this.
\newcommand{\theorem}{\noindent {\bf \addtocounter{subsubsection}{1} \arabic{section}.\arabic{subsubsection}  Theorem.} }

% I tend not to use these, and instead use tpoint above.
\newtheorem{tm}{Theorem}[subsection]\newtheorem{pr}[tm]{Proposition}\newtheorem{lm}[tm]{Lemma}\newtheorem{co}[tm]{Corollary}\newtheorem{df}[tm]{Definition}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% fonts

% miscellaneous

\newcommand{\uR}{\underline{\R}}
\newcommand{\M}{M}
\newcommand{\vv}{\vec{v}}

%\newcommand{\ut}[1]{\underset{\widetilde{ }}{#1}}

% tilde
\newcommand{\tK}{\tilde{K}}
\newcommand{\tA}{\tilde{A}}
\newcommand{\tX}{\tilde{X}}
\newcommand{\tY}{\tilde{Y}}
\newcommand{\tZ}{\tilde{Z}}
\newcommand{\tC}{\tilde{C}}
\newcommand{\tS}{\tilde{S}}

%  overline

\newcommand{\cmbar}{\overline{\cm}}
\newcommand{\Fpbar}{\overline{\F}_p}
\newcommand{\oz}{\overline{z}}
\newcommand{\ow}{\overline{w}}


\newcommand{\Qbar}{\overline{\mathbb{Q}}}
\newcommand{\Ebar}{\overline{E}}
\newcommand{\kbar}{\overline{k}}
\newcommand{\wbar}{\overline{w}}

% bb
\newcommand{\proj}{\mathbb P}

\newcommand{\C}{\mathbb{C}}
\newcommand{\F}{\mathbb{F}}
\newcommand{\G}{\mathbb{G}}
\renewcommand{\H}{\mathbb{H}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\A}{\mathbb{A}}
\newcommand{\E}{\mathbb{E}}
\renewcommand{\L}{\mathbb{L}}
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\W}{\mathbb{W}}
\newcommand{\bbS}{\mathbb{S}}
\newcommand{\R}{\mathbb{R}}
\def\CC{\mathbb{C}}
\def\DD{\mathbb{D}}
\def\EE{\mathbb{E}}
\def\FF{\mathbb{F}}
\def\GG{\mathbb{G}}
\def\HH{\mathbb{H}}
\def\II{\mathbb{I}}
\def\JJ{\mathbb{J}}
\def\KK{\mathbb{K}}
\def\LL{\mathbb{L}}
\def\MM{\mathbb{M}}
\def\NN{\mathbb{N}}
\def\OO{\mathbb{O}}
\def\PP{\mathbb{P}}
\def\QQ{\mathbb{Q}}
\def\RR{\mathbb{R}}
\def\SS{\mathbb{S}}
\def\TT{\mathbb{T}}
\def\UU{\mathbb{U}}
\def\VV{\mathbb{V}}
\def\WW{\mathbb{W}}
\def\XX{\mathbb{X}}
\def\YY{\mathbb{Y}}
\def\ZZ{\mathbb{Z}}

% scr and mathcal
\newcommand{\cA}{{\mathscr{A}}}
\newcommand{\cB}{{\mathscr{B}}}
\newcommand{\cC}{{\mathscr{C}}}
\newcommand{\cE}{{\mathscr{E}}}
\newcommand{\cF}{{\mathscr{F}}}
\newcommand{\cG}{{\mathscr{G}}}
\newcommand{\cI}{{\mathscr{I}}}
\newcommand{\cJ}{{\mathscr{J}}}
\newcommand{\cK}{{\mathscr{K}}}
\newcommand{\cLL}{{\mathscr{L}}}
\renewcommand{\cL}{{\mathscr{L}}}
\newcommand{\cm}{{\mathscr{M}}}
\newcommand{\cM}{{\mathscr{M}}}
\newcommand{\cP}{{\mathscr{P}}}
\newcommand{\cQ}{{\mathscr{Q}}}
\newcommand{\cS}{{\mathscr{S}}}
\newcommand{\cT}{{\mathscr{T}}}
\newcommand{\cu}{{\mathscr{U}}}
\newcommand{\cV}{{\mathscr{V}}}
\newcommand{\cW}{{\mathscr{W}}}
\newcommand{\cX}{{\mathscr{X}}}
\newcommand{\cY}{{\mathscr{Y}}}
\newcommand{\ct}{{\mathscr{T}}}
\newcommand{\oh}{{\mathscr{O}}}

\def\calF{\mathcal{F}}
\def\calG{\mathcal{G}}
\def\calH{\mathcal{H}}
\def\calI{\mathcal{I}}
\def\calJ{\mathcal{J}}
\def\calK{\mathcal{K}}
%\newcommand{\calL}{{\mathscr{L}}}
\def\calL{\mathcal{L}}
\def\calM{\mathcal{M}}
\def\calN{\mathcal{N}}
\def\calO{\mathcal{O}}
\def\calP{\mathcal{P}}
\def\calQ{\mathcal{Q}}
\def\calR{\mathcal{R}}
\def\calS{\mathcal{S}}
\def\calT{\mathcal{T}}
\def\calU{\mathcal{U}}
\def\calV{\mathcal{V}}
\def\calW{\mathcal{W}}
\def\calX{\mathcal{X}}
\def\calY{\mathcal{Y}}
\def\calZ{\mathcal{Z}}

% bf
\def\bU{\mathbf{U}}
\def\bV{\mathbf{V}}
\def\bW{\mathbf{W}}
\def\bX{\mathbf{X}}
\def\bY{\mathbf{Y}}
\def\bZ{\mathbf{Z}}
\newcommand{\D}{\mathbf{D}}

\def\bJ{\mathbf{J}}
\def\bK{\mathbf{K}}
\def\bL{\mathbf{L}}
\def\bM{\mathbf{M}}
\def\bN{\mathbf{N}}
\def\bO{\mathbf{O}}
\def\bP{\mathbf{P}}
\def\bQ{\mathbf{Q}}
\def\bR{\mathbf{R}}
\def\bS{\mathbf{S}}
\def\bT{\mathbf{T}}
\def\bU{\mathbf{U}}
\def\bV{\mathbf{V}}
\def\bW{\mathbf{W}}
\def\bX{\mathbf{X}}
\def\bY{\mathbf{Y}}
\def\bZ{\mathbf{Z}}


% frak

\newcommand{\fm}{\mathfrak{m}}
\newcommand{\fr}{\mathfrak{r}}
\newcommand{\fM}{{\mathfrak{M}}}
\newcommand{\fU}{{\mathfrak{U}}}

\newcommand\frA{\mathfrak{A}}
\newcommand\frB{\mathfrak{B}}
\newcommand\frg{\mathfrak{g}}
\newcommand\frt{\mathfrak{t}}
\newcommand\frb{\mathfrak{b}}
\newcommand\frh{\mathfrak{h}}
\newcommand\frn{\mathfrak{n}}
\newcommand\frN{\mathfrak{N}}
\newcommand\frl{\mathfrak{l}}
\newcommand\frp{\mathfrak{p}}
\newcommand\frq{\mathfrak{q}}
\newcommand\frr{\mathfrak{r}}
\def\frm{\mathfrak{m}}



%%%%%%%% tilde %%%%%%%%%


\newcommand\tilW{\widetilde{W}}
\newcommand\tilA{\widetilde{A}}
\newcommand\tilB{\widetilde{B}}
\newcommand\tilC{\widetilde{C}}
\newcommand\tilD{\widetilde{D}}
\newcommand\tilE{\widetilde{E}}
\newcommand\tilF{\widetilde{F}}
\newcommand\tilG{\widetilde{G}}

%%%%%%%% hat %%%%%%%%%

\def\hatG{\widehat{G}}
\newcommand\hA{\widehat{A}}
\newcommand\hLam{\widehat{\Lambda}}
\newcommand\hZ{\widehat{\ZZ}}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% symbols


% greek 

\newcommand{\al}{\alpha}
\newcommand{\ka}{\kappa}

\newcommand{\om}{\omega}
\newcommand{\be}{\beta}
\newcommand{\ga}{\gamma}
\newcommand{\Ga}{\Gamma}
\newcommand{\de}{\delta}
\newcommand{\De}{\Delta}
\newcommand{\si}{\sigma}
\newcommand{\la}{\lambda}

% other

\newcommand{\dis}{\bullet}
\newcommand{\virt}{\rm{virt}}
\newcommand{\Kvar}{K_{(\rm{Var})}}
\newcommand{\fixed}{\rm{fixed}}
\newcommand{\Add}{\rm{Add}}
\renewcommand{\top}{\rm{top}}
\newcommand{\red}{\rm{red}}

\newcommand{\coloneq}{:=}



\newcommand{\propernormal}{%
  \mathrel{\ooalign{$\lneq$\cr\raise.22ex\hbox{$\lhd$}\cr}}}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% operatornames

\newcommand{\opn}[1]{\operatorname{#1}}

%\newcommand{\spam}{\operatorname{span}}

% category theory
\newcommand{\cat}[1]{{\text{\underline{\bf #1}}}}
\newcommand{\colim}{\operatorname{colim}}
\newcommand{\Ext}{\operatorname{Ext}}
\newcommand{\Mor}{\operatorname{Mor}}
\newcommand{\Isom}{\operatorname{Isom}}
\newcommand{\same}{{\overset {\displaystyle \sim} \longleftrightarrow}}
\newcommand{\sametwo}{\xrightarrow{\sim}}

% group and ring theory
\newcommand\Stab{\operatorname{Stab}}
\newcommand{\Orb}{\operatorname{Orb}}
\newcommand{\Sym}{\operatorname{Sym}}
\newcommand{\Aut}{\operatorname{Aut}}
\newcommand{\rank}{\operatorname{rank}}
\renewcommand{\span}{\operatorname{span}}
\newcommand{\coker}{\operatorname{coker}}
\newcommand{\val}{\operatorname{val}}
\newcommand{\chr}{\operatorname{char}}
\newcommand{\Gal}{\operatorname{Gal}}
\newcommand{\Ad}{\operatorname{Ad}}
\newcommand{\uGal}{\underline{\Gal}}
\newcommand{\Hom}{\operatorname{Hom}}
\newcommand{\Fn}{\operatorname{Maps}}
\newcommand{\Maps}{\operatorname{Maps}}


% algebraic geometry
\newcommand{\codim}{\operatorname{codim}}
\newcommand{\Div}{\operatorname{Div}}
\newcommand{\Hilb}{\operatorname{Hilb}}
\newcommand{\Pic}{\operatorname{Pic}}
\newcommand{\Spec}{\operatorname{Spec}}
\newcommand{\Cl}{\operatorname{Cl}}
\newcommand{\res}{\operatorname{res}}
\renewcommand{\div}{\operatorname{div}}
\newcommand{\Trop}{\operatorname{Trop}}
\newcommand{\Jac}{\operatorname{Jac}}

\newcommand{\aff}{\rm{aff}}

\newcommand{\Gr}{\rm{Gr}}
\newcommand{\LGr}{\rm{LGr}}
\newcommand{\SAG}{\rm{SpAfGr}}
\newcommand{\LSG}{\rm{LgStGr}}

% define \jalpha so that it can be used in math mode
\newcommand{\jalpha}{\mathord{j\mkern-7mu\alpha}}
%\newcommand{\jalpha}{  \overset{\alpha}{j}}
\newcommand{\vjalpha}{\vec{\jalpha}}

\newcommand{\Id}{\rm{Id}}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% editing commands


%\newcommand{\remind}[1]{{\bf[#1]}}
\newcommand{\remind}[1]{{\bf[{\large TODO:  } #1]}}
\newcommand{\lremind}[1]{{\bf[label:  #1]}}
%\newcommand{\notation}[1]{\footnote{\scriptsize #1}}
\newcommand{\notation}[1]{}
%\renewcommand{\remind}[1]{{}}
\renewcommand{\lremind}[1]{{}}

\newcommand{\ravi}[1]{{\bf [#1 --- Ravi]}}
\newcommand{\hidden}[1]{\footnote{Hidden:  #1}}
%\renewcommand{\hidden}[1]{}

\newcommand{\cut}[1]{}
%\newcommand{\cut}[1]{#1}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% formatting commands

\newcommand{\leftbox}[1]{      \begin{flushleft}\fbox{ \parbox{25em}{
#1        }}\end{flushleft}
}\newcommand{\centerbox}[1]{      \begin{center}\fbox{ \parbox{25em}{
#1        }}\end{center}
}
\newcommand{\rightbox}[1]{      \begin{flushright}\fbox{ \parbox{25em}{
#1        }}\end{flushright}
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% end of preamble

\begin{document}
\pagestyle{plain}
\title{\Large{$\Omega^2(BSp)$ notes}}
\author{Ravi Vakil for Jim Bryan}
%\address{Dept. of Mathematics, Stanford University, Stanford CA~94305--2125}
%\email{rvakil@stanford.edu}
\date{\today .   {\em Last edited:}
 Sunday, July 27, 2025. (keep current date here)  }
%\date{March 23 2021}
%\subjclass{Primary 14F30, Secondary 14F20. }
%\begin{abstract}
% \end{abstract}
\maketitle
\tableofcontents


{\parskip=12pt % closing bracket is just before the bibliography 



  
  These are Ravi's notes, for Jim.


  \section{Initial setting of notation}

  $\boxed{x} = \boxed{x_0} / \boxed{x_1}$.  $\boxed{p_{\infty}} = \infty = V(x_0)$.
  (So caution: I think it is not $V(x_1)=[1,0]$.)

 $\boxed{z} = y= t = x_1/x_0$ is the coordinate near $\infty$.

\epoint{The space $V$}

We start with a vector space $\boxed{U=V}$ with an alternating form. 
(I expect everything I type here to work fine for $O$ in place of $Sp$  with change of signs, but I stick to the symplectic case for concreteness and to avoid confusion.) 
Choosing a splitting $V = L \oplus L^*$ is called a polarization or Lagrangian splitting. Jim says it is a "Weinstein normal form".

More generally, we can work over an arbitrary base, and all statements will behave well with respect to base change.
So most generally, we work over $\Spec \Z$, and $V$ is a free sheaf on $\Spec \Z$ of rank $\boxed{\boxed{2n}}$, etc.
Caution:  $\dim U=n$ in earlier discussions.
I will continue to use vector space language for simplicity.

Note that $\boxed{\boxed{\dim LG(V)= n(n+1)/2}}$.  (In the orthogonal case, it is $\boxed{\boxed{\dim OG(V)= n(n-1)/2}}$.)


\section{Background on the symplectic affine Grassmannian}


\epoint{The loop space of $V$}

The loop space of $V$ is
$$\boxed{H} = \boxed{V((z))} \coloneq V[[z]] \oplus z^{-1} V[ z^{-1}].$$


We define
$\boxed{H^+} = V[[z]]$ and $\boxed{H^-} = z^{-1} V[ z^{-1}]$.
$H$ has a residue pairing:  
$$\boxed{\langle f(z), g(z) \rangle} \coloneq \operatorname{Res}_{z=0}  \omega(f(-z), g(z)) \; dz.$$
This residue pairing is skew-symmetric and nondegenerate.
$H$ is thought of as some sort of infinite-dimensional symplectic Hilbert space.


{\em Question:} What's the reason for the sign in pairing?  
I think in our pairing (see later on), there is no sign.


\epoint{The Lagrangian Sato Grassmannian} 

The Lagrangian Sato Grassmannian parametrizes "Lagrangians" of the loop space that are close to $H^+$.
It is contained in the index zero component of the (usual --- not symplectic) Sato Grassmannian (not defined here).
The Lagrangian Sato Grassmannian  is often denoted $\LGr_\infty$ (or $LGr(H)$).  I will use temporary notation $\boxed{\LSG}$ to remind us of its meaning. (This is a macro which can be easily changed.)


The $N$th truncation is denoted $\boxed{\LSG^{(N)}} = \LSG^{(N)}(H)$, and is isomorphic to $$LG(N \dim V, 2N \dim V).$$
We can show that $\LSG_\infty$ is the limit of $LGr(nN, 2nN)$ in our naive homotopy category.   Thus its homotopy type is $LGr(\infty, 2 \infty) = U/O = \Omega(Sp)$.

Remark:
This will likely be relevant for us, because we will be "increasing $V$" which will be changing the symplectic affine Grassmannian, but the ambient Lagrangian Sato Grassmannian (even for finite $V$) will be what we want.  

\epoint{The symplectic affine Grassmannian}

The symplectic affine Grassmannian is the $z$-stable locus inside the Lagrangian Sato Grassmannian.
The symplectic affine Grassmannian is  unfortunately 
often denoted  $Gr$ or $Gr_{Sp_{2n}}$ or $Gr_{Sp}$. I will use temporary notation $\boxed{\SAG}$ to remind us.  This is a temporary macro which can be easily changed.

Fact:  $\SAG_{Sp(V)}$ is homotopic to $\Omega(Sp(V))$.

Vague argument (that I've not thought through):    $L Sp(V)$ parametrizes maps from loops to $Sp(V)$ --- smooth maps from $S^1$.  $\boxed{L^+} =L^+(V)$ is the subset where the map extends holomorphically to the disk.  Then show that $L/L^+ \cong LGr$, by describing a transitive action of $L$, and identifying the stabilizer as $L^+$.  But $L^+$ is contractible.  (Presumably I should look at \cite{ps} for more. It might be in a later paper of  Nadler, perhaps \cite{nadler}, see one of the references of \cite{zhu}.)   (There is an argument of this sort in the algebraic category, involving algebraic loops; and also in the continuous category.)

\epoint{Truncations of the symplectic affine Grassmannian}
The $N$th truncation of the symplectic affine Grassmannian is 
called $\boxed{\SAG_{Sp}^{(N)}} = \Gr^{(N)}$.  (Caution:  I am worried that the terminology  $\Gr$  gets used both for the affine and the Sato case.)

Here are some interesting facts from \cite{zhu}.
I'm not sure, but I think \begin{equation}\label{eq:dimsag}
  \dim \SAG^{(N)} = \boxed{\boxed{N (2n-1)}}.
\end{equation}
(The orthogonal case would be $\boxed{\boxed{N(2n-2)}}$.)
This perhaps could be unwound from \cite[S 2.3]{zhu}.  (Perhaps investigate
S. Kumar, Kac–Moody Groups, their Flag Varieties and Representation Theory, around \S 10.2.)
Also from 
\cite[Thm.~2.1.21]{zhu}:  singularities are normal, Cohen-Macaulay, Gorenstein, and rational singularities.   He refers to Faltings \cite[ref.\ 24]{zhu}, Pappas-Rapoport \cite[ref.\ 60]{zhu}, Beilinson-Drinfeld \cite[ref.\ 11]{zhu}, and Zhu \cite[ref.\ 80]{zhu}.

\epoint{Singularities of the truncation}
Apparently $\SAG^{(N)}$  is singular in codimension $\dim V$, with possible reference  \cite{mov}. 


\section{Introduction to moduli of vector bundles with symplectic structure:  $A$, $j$, $\alpha$, $X(d)$}

Now let $\boxed{\Omega^2_{alg}(BSp(2n))}$  be the moduli space of vector bundles on $\proj^1$, framed at $p_\infty$ by $V$, with its form.

Let $\boxed{\Omega^2_{alg}(BSp(2n))^{[N]}}$ parametrize those bundles $\cF$ such that $\cF(N)$ is globally generated. For example, 
$\Omega^2_{alg}(BSp(2n))^{[N]}$ is empty if $N<0$.

\epoint{Basic facts about this space}
The space 
$\Omega^2_{alg}(BSp(2n))$ 
is an Artin stack.  

 The space 
$\Omega^2_{alg}(BSp(2n))$ is an $Sp(2n)$ bundle over the "unframed" moduli space, which is also thus an Artin stack.  This latter space is smooth, because the automorphisms/deformation/obstructions of a principle bundle $E$ is given by the cohomology of the adjoint bundle $ad(E)$, so automorphisms are $H^0(ad(E))$, deformations are $H^1(ad(E))$, and obstructions are $H^2(ad(E))$, which in this case are zero.  (The adjoint bundle is the "twisted Lie algebra bundle", as I think Jim was telling me.)



The space 
$\Omega^2_{alg}(BSp(2n))$  is the union of an increasing sequence of open substacks
$\Omega^2_{alg}(BSp(2n))^{[N]}$.

Each $\Omega^2_{alg}(BSp(2n))^{[N]}$ is quasicompact and finite type.  

$\Omega^2_{alg}(BSp(2n))^{[0]}$ is a reduced point.

The space of  bundles trivialized in a formalized neighborhood of $p_\infty$ is apparently, as an ind-scheme, the affine symplectic Grassmannian $\SAG{Sp(2n)}$.

\epoint{Sketch of why these things are true}
These are all well-known facts, but we will also end reproving them, so we can have confidence in these statements.  Here is the architecture of our argument.

First:
$\Omega^2_{alg}(BSp(2n))$ and $\Omega^2_{alg}(BSp(2n))^{[N]}$
are stacks in the usual (smooth etc.) topology (not yet obviously algebraic stacks).  

(ii) 
We construct a finite type affine scheme (explicitly, with generators and relations), that will parametrize the same things as  $\Omega^2_{alg}(BSp(2n))^{[N]}$, with in addition a Zariski-splitting.  This is an affine bundle  over $\Omega^2_{alg}(BSp(2n))^{[N]}$.  Thus $\Omega^2_{alg}(BSp(2n))^{[N]}$ is an algebraic stack (i.e., an Artin stack).

We  have open embeddings of these truncations, and their union is  the entire space, so $\Omega^2_{alg}(BSp(2n))$ is an algebraic stack.




$\Omega^2_{alg}(B Sp(V))$ parametrizes the following.

\begin{itemize}
\item $\boxed{\cF}$ is a rank $2n$ vector bundle on $\proj^1$.  (Caution:  earlier the bundle on $\proj^1$ was considered to be rank $n$.)
\item  We have an identification $\cF|_{p_{\infty}} \overset \sim \longrightarrow V$
\item $\boxed{\phi_\cF}: \cF \overset \sim \longrightarrow \cF^\vee$ satisfying 
$\phi^\vee_\cF = -\phi_\cF$, and $\phi_{\cF}|_{p_\infty} = \phi_V$ (where $\phi_V$ comes
from the alternating form).    Or equivalently:  $\boxed{\psi_{\cF}}: \cF\otimes \cF \rightarrow \oh$,
with appropriate hypotheses.
\end{itemize}


\epoint{Comparison to topology}
I think we quote Cohen-Lupercio-Segal or someone else to show that smooth maps to $BSp(V)$ are homotopic to holomorphic maps to $BSp(V)$.
Then by GAGA (some justification needed) this is the same as algebraic maps to $BSp(V)$.

\point $\boxed{\Omega^2_{d,alg}(B Sp(V))}$ parametrizes the same, with the additional requirement that $\cF(d p_\infty)$ is
generated by global sections.  (Equivalently, when you write $\cF$ as a direct sum of line bundles, the summands
are all of degree between $-d$ and $d$ inclusive.  This interpretation is {\em not helpful}.)

$\boxed{d=N}$:  Jim and I used $d$, and the affine Grassmannian people use $N$. 

We define $\boxed{\cE} = \cF (d p_{\infty})$ for convenience.  This bundle is rank $2n$ and 

We then have $\boxed{\phi_{\cE}} : \cE \rightarrow \cE^\vee(2d)$, and \begin{equation}
  \boxed{\psi_{\cE}} = \psi_{\cF}(2d) : \cE \otimes \cE \rightarrow \oh(2d p_{\infty}).
  \label{eq:p20}
  \end{equation}

\tpoint{Claim}
{\em We have an induced isomorphism $\cE|_{p_{\infty}} \overset \sim \longrightarrow V$.}

(Proof omitted.)

\epoint{Zariski-framing}

Define $\boxed{A}  \coloneq H^0(\cE(-p_\infty))$.   $\cE$ has rank $2n$ and degree $2nd$.
Thus $\dim A = 2n(d-1) + 2n = 2nd$.   $\boxed{\boxed{\dim A = 2nd}}$

\point We now consider the Zariski-framed moduli space, which doesn't yet have a name. I temporarily dub it $\boxed{X(d)}$.  $\dim X(d)  = (\dim A)(\dim U)= (2dn)(2n)=4dn^2$. $\boxed{\boxed{\dim X(d) = 4dn^2}}$\label{s:dimXd}

\point The data of the Zariski-framed bundle $\cE$ is the data of $A$, plus $\boxed{\al}: A \rightarrow A$, and $\boxed{j}:A \rightarrow U$,
along with an {\em open condition} on $j$ and $\al$.

The following matrix (where we are treating elements of $A$ and $U$  as column vectors) is required
to be full rank for all $x \in \C$.

\begin{tabular}{|ccc|}
  \hline
  & &  \\
  & $x \rm{Id}-\al$ &  \\
  & &  \\
\hline
& $j$ &  \\
\hline
\end{tabular}

This matrix has $\dim A + \dim U$ rows and $\dim A^\vee$ columns.  Better:  the top block's rows are parametrized by $A$; the bottom block's rows are parametrized by $U$; and the colums are parametrized by $\A^\vee$.  I might write this as:


\begin{tabular}{|ccc|c}
  \hline
  & & & \\
  & $x \rm{Id}-\al$ & & $A$ \\
  & & & \\
\hline
& $j$ & & $U$ \\
\hline
& $A^\vee$ & &  \\
\end{tabular}



For each $x \in \C$, the locus where the matrix is not full rank is codimension $2n+1$.
Thus as $x$ varies, the locus where the matrix is not full rank is codimension $\boxed{\boxed{2n}}$.
(That's not quite rigorous.)

\bpoint{$\jalpha$ and $\vjalpha$}

For future use, define $\jalpha: A \rightarrow t U[[t]]$ by
$$\boxed{\jalpha} = j t + j \al  t^2 + j \al^2  t^3 + \cdots = jt/(1-t\alpha)$$
This is the generating function for $j \al^{k-1}$.

We also define
$$
\boxed{\vjalpha} \coloneq
\begin{pmatrix}
j \\
  j \alpha \\
  \vdots \\
j \alpha^{2d}
\end{pmatrix} : A \rightarrow U^{\oplus 2d}
$$
so roughly $\vjalpha = 
\jalpha \pmod t^{2d+1}$.

\tpoint{Claim}   {\em $\vjalpha$ is an injection $A \hookrightarrow U^{\oplus 2d}$.
}

{\bf Jim says this is the same as as the open condition on $j$ and $\alpha$; type this in soon.}

\epoint{Sketch of proof}

Consider $0 \rightarrow \cE(-2d-1) \rightarrow \cE(-1) \rightarrow \cE(-1)/\cE(-2d-1) \rightarrow 0.$
Now $\cE$ is the direct sum of line bundles with degrees at most $2d$,
so $H^0(\cE(-2d-1)=0$ from which
$$
H^0(\cE(-1)) \rightarrow H^0(\cE(-1)/ \cE(-2d-1))$$ is an  injection. \epf

Now $A$ has rank $2dn$, and  the right side has rank $4dn$.

\epoint{Recovering $(A, j, \al)$ from this subset of $t U \oplus \cdots \oplus t^{2d} U \oplus t^{2d+1} U$ (take one)}

$A$ is just the subset.

$j$ is just $[t] \jalpha$.

We can almost get $\al$, but not quite. We can recover it from the image in
$tU \oplus \cdots t^{2d+2}U$:  simply truncate the first and slide left.
The key missing piece (that we fill in later):  how can we get $j \alpha^{2d} a$ if we know $j \alpha^s a$ for $0 \leq s < 2d$?


\section{Mixing in the inner product}

\bpoint{Relationships between $(\al, j)$ and the  pairing $(\psi_\cE/\phi_\cE)$}

We unpack \eqref{eq:p20}.  Induced by $H^0(\cF(d))) \otimes H^0(\cF(d)) \rightarrow H^0(\oh(2d))$ is
$$
\boxed{\psi_{A \oplus U}} : \underbrace{(A \oplus U)}_{\text{dim}=(d+1)(2n)} \otimes (A \oplus U) \rightarrow \C[x_0, x_1]_{2d}$$
where the subscript means ``homogeneous of degree $2d$.'' Equivalently,
$$
\boxed{\phi_{A \oplus U}} : A \oplus U \rightarrow (A^\vee \oplus U^\vee)[x_0, x_1]_{2d}$$
satisfying \begin{equation}
  \label{eq:phivee}
  \phi_{A \oplus U} = - \phi^\vee_{A \oplus U},
  \end{equation}
satisfying three conditions:
\begin{enumerate}
\item[(V)] ``vanishes on $(x-\al, -j)$'' (on either factor, but \eqref{eq:phivee} means we need only the first factor) (closed condition) and
  \item[(ND)]  ``nondegenerate on the quotient for all $x \in \C$''  (open condition)
  \item[(BP)] $[x_0^{2d}] \psi_{A \oplus U} ( (a_1, u_1), (a_2, u_2)) = \psi_U(u_1, u_2)$ (base point condition, hence nondegeneracy at $x =\infty$) 
\end{enumerate}

The following is then tautological.

\tpoint{Claim} {\em This precisely parametrizes our space. Hence our space $X(d)$ is a quasiaffine variety.}

We unpack this.  (Notice that with this description, it will not be obvious that $X(d)$ is smooth!)

We write the components of $\phi$ out explicitly as follows.

Define
$$\xymatrix{\boxed{T_A}: A \rightarrow A^\vee[x_0, x_1]_{2d} &
T_A = T_{A,0}x_0^{2d} + \cdots + T_{A,2d} x_1^{2d} & \text{so } T_{A,i}^\vee = - T_{A,i} & T_{A,0}=0 \\
  \boxed{T_U}: U \rightarrow U^\vee[x_0, x_1]_{2d} & T_U = T_{U,0}x_0^{2d} + \cdots + T_{U,2d} x_1^{2d} & \text{so } T_{U,i}^\vee = - T_{U,i} & T_{U,0}=\phi_U  \\
  \boxed{T_{AU}}: A \rightarrow U^\vee[x_0, x_1]_{2d} & T_{AU} = T_{AU,0}x_0^{2d} + \cdots + T_{AU,2d} x_1^{2d} &  & T_{AU,0}=0
}$$
and $\boxed{T_{UA}} = - T_{AU}^\vee: U \rightarrow A^\vee[x_0, x_1]_{2d}$

The final column gives the third condition (BP).

Condition (V) translates to
$$
\phi_{A \oplus U}(  (x_0-x_1 \al) a, -x_1 ja) =0 \in A^\vee \oplus U^\vee$$
for any $x =x_0/x_1 \in \C$, $a \in A$.  

The $A^\vee$ component of this gives:
$$
0 = \sum x_0^{2d-1-i} x_1^i \left( T_{A,i} (x_0a -x_1 \al(a)) +  T_{AU,i}^\vee  (j(a) x_1) \right)
$$
The $U^\vee$ component of this gives:
$$0 = \sum x_0^{2d-1-i} x_1^i \left( T_{AU,i} (x_0a -x_1 \al(a)) +  T_{U,i}  (-j(a) x_1) \right)
$$

We thus have two sequences of $2d+2$ conditions from these.   From the coefficients of $x_0^{2d-1-i} x_1^{i+1}$ (where $i$ runs from $-1$ to $2d$):
\begin{equation}\label{eq:TArecursion}
  0 = T_{A, i+1} - T_{A,i} \circ \al - T_{AU,i}^\vee \circ j : A \rightarrow A^\vee
  \end{equation}
and
\begin{equation}\label{eq:TAUrecursion}
  0 = T_{AU, i+1}   - T_{AU,i} \circ \al + T_{U,i} \circ j: A \rightarrow U^\vee
  \end{equation}
The  case $i=-1$ is the previously-stated relations $T_{A,0}=0$ and $T_{AU,0}=0$.

Thus the closed condition (V) means that if we choose $T_{U,i}$ freely for $i=1, \dots, 2d$,
then the $T_{AU,i}$ and $T_{A,i}$ are determined inductively from the cases $i=0$ through $2d-1$.
The two remaining conditions when $i=2d$ give us relations.

\epoint{Checking dimensions so far}
Now our choices of $j$ and $\al$ give us $(\dim A)(\dim U) = \dim X(d)$ dimensions already
$T_{U,i}:U \rightarrow U^\vee$ must satisfy $T_{U,i} = - T_{U, i}^\vee$, so the dimension
of choices of one of them is $1 + \cdots+ (2n-1) = (2n-1)(2n)/2= n(2n-1)$ (roughly $(\dim U)^2/2$).
Thus the total number of choices is for all of them is $2dn(2n-1)=4dn^2-2dn$.
So our new conditions for $i=2d$ must give us precisely this many relations, and also cut out something smooth!


\bpoint{Towards the two conditions}

Recall $z=x_1/x_0$.  Define $\boxed{T_{AU}} \coloneq \sum T_{AU,i} z^i :  A \rightarrow U^\vee[[z]]$, and similarly for $\boxed{T_U} : U \rightarrow U^\vee[[z]]$ and $\boxed{T_A}: A \rightarrow A^\vee$ (and $\boxed{T_{UA}} = -T_{AU}^\vee: U \rightarrow A^\vee[[z]]$).  These are all actually polynomials of degree (at most) $2d$, but I wish to deliberately consider them as power series.

\tpoint{Claim}  {\em $T_{AU} = - T_U \jalpha$ and $T_{UA} = \jalpha^\vee T_U$.}

\bpf From \eqref{eq:TAUrecursion}
$$
0 = T_{AU, i+1}   - T_{AU,i} \circ \al + T_{U,i} \circ j: A \rightarrow U^\vee$$
we have
$T_{AU} - T_{AU} \al z + T_U jz = 0$ from which $T_{AU} (1-\al z) = - T_U jz$ from which
$T_{AU} = -T_U jz / (1-\al z) = - T_U \jalpha$. \epf

\tpoint{Claim} {\em $T_A = T_{AU}^\vee \jalpha = \jalpha^\vee T_U \jalpha$.}

\bpf From \eqref{eq:TArecursion}
$$
0 = T_{A, i+1} - T_{A,i} \circ \al - T_{AU,i}^\vee \circ j : A \rightarrow A^\vee$$
we have
$T_A - T_A \al z - T_{AU}^\vee j z = 0$ from which $T_A = T_{AU}^\vee \jalpha = \jalpha^\vee T_U \jalpha$. \epf

\bpoint{First closed condition}

From condition \eqref{eq:TAUrecursion}, $T_{AU} = T_U \jalpha$,
$$
-T_{AU} = \left( T_{U,0} + T_{U,1} z + \cdots + T_{U,2d} z^{2d} \right) \left( jz + j \alpha z ^2 + \cdots \right).$$
The coefficient of $z^{2d+1}$ is:
$$
-T_{AU,2d+1}=T_{U,0} j \al^{2d} + T_{U,1} j \al^{2d-1} + \cdots + T_{U,2d} j \al^0
$$
Indeed, more generally, for $s \geq 0$
$$
-T_{AU,2d+1+s}=-T_{AU,2d+1} \circ \al^s
$$
so our countably many conditions ensuring that $T_{AU}$ is a polynomial of degree $2d$ is just one condition:
\begin{equation}\label{eq:first}
\boxed{T_{U,0} j \al^{2d} + T_{U,1} j \al^{2d-1} + \cdots + T_{U,2d} j \al^0 = 0 \in \Hom(A, U^\vee).}
\end{equation}
This is a linear condition of dimension $(\dim A)(\dim U)$.

\tpoint{Corollary}{\em  The first closed condition \eqref{eq:first} can be rewritten in the following two useful ways.
  (a)
  $$
  j \al^{2d} = 
  -T^{-1}_{U,0} T_{U,1} j \al^{2d-1} - \cdots  -T^{-1}_{U,0} T_{U,2d} j \al^0 \in \Hom(A, U^\vee).$$
  (b)
  $$  T_{U} j \al^{2d} + 
  \begin{pmatrix} T_{U,2d-1} & \hdots & T_{U,1} & T_{U,0}
  \end{pmatrix} \vjalpha = 0 \in \Hom(A, U^\vee)
  $$
  }


  \bpoint{Second closed condition}

From condition \eqref{eq:TArecursion}, it is best to use the form $T_{A,2d+1} = T_{AU}^\vee \jalpha$.
The analogous argument gives the single condition
$$
T^\vee_{AU,0} j \al^{2d} + T^\vee_{AU,1} j \al^{2d-1} + \cdots + T^\vee_{AU,2d} j \al^0 = 0 \in \Hom(A, A^\vee)
$$
or equivalently 
$$
(\al^\vee)^{2d} j^\vee T_{AU,0}  + (\al^\vee)^{2d-1} j^\vee T_{AU,1} + \cdots + (\al^\vee)^0 j^\vee T_{AU,2d} = 0 \in \Hom(A, A^\vee)
$$
from which
\begin{equation}\label{eq:second}\boxed{
\left(   (\al^\vee)^{2d-1}  ( j^\vee T_{U,0} j)   \al^0 + 
  (\al^\vee)^{2d-2}  ( j^\vee T_{U,0} j)   \al^1 +  \cdots  +
  (\al^\vee)^{0}  ( j^\vee T_{U,0} j)   \al^{2d-1} \right) +  }\end{equation}
$$
\boxed{\left(   (\al^\vee)^{2d-2}  ( j^\vee T_{U,1} j)   \al^0 +   \cdots  +
    (\al^\vee)^{0}  ( j^\vee T_{U,1} j)   \al^{2d-2} \right) + \cdots + 
\left( j^\vee T_{U,2d-1} j \right) = 0}$$


\tpoint{Corollary} \label{c:second}
{\em This can be rewritten as:
\begin{equation}\label{eq:Tmatrix}
 \vjalpha^\vee
 \begin{pmatrix}
T_{U,2d-1} & T_{U,2d-2} &  T_{U,2d-3} &  \hdots & T_{U,1} & T_{U,0} \\
 T_{U,2d-2} &  T_{U,2d-3} & T_{U,2d-4} &  \hdots & T_{U,0} & 0 \\
   \vdots  & \vdots  &   \vdots  & \ddots & \vdots & \vdots \\
   T_{U,1} & T_{U,0} & 0 & \hdots & 0 & 0 \\
   T_{U,0} & 0 & 0 & \hdots & 0 & 0 
  \end{pmatrix}
 \vjalpha =0 \in \Hom(A,A^\vee)
\end{equation}
}

Note that this \boxed{$T$-matrix} is invertible and alternating, and thus gives a symplectic structure to $U^{\oplus 2d}$.


\tpoint{Theorem}  \label{t:preliminaryform}{\em Recall that we given $d$, $U$, and $T_U: U \rightarrow U^\vee$ (invertible, signed).
  $X(d)$ is paramatrized by precisely the following information.
  We need $T_{U,1}$, \dots, $T_{U,2d}: U \rightarrow U^\vee$ with $T_{U,i}^\vee = - T_{U,i}$ (and define $T_{U,0}=T_U$). Then $X(d)$ consists of the space parametrizing half-dimensional subspaces $\boxed{A'}$ of $U^{\oplus 2d}$ such that (i)
  $A'$ is ``(maximal) isotropic with respect to the $T$-matrix'' 
 (see Corollary~\ref{c:second}), such that furthermore
(ii)  under the linear map $\al' : U^{2d} \rightarrow U^{2d}$ defined by  $$\boxed{\al'}: (u_0, u_1, \dots, u_{2d-2}, u_{2d-1}) \mapsto
 (u_1, u_2, \dots, u_{2d-1},
 -T^{-1}_{U,0} T_{U,1} u_{2d-1}  - \cdots  -T^{-1}_{U,0} T_{U,2d} u_0 )$$
 $A'$ maps to $A'$.  (iii) then we have an open condition, given by the induced $j$ and $\alpha$ (ensuring that we build a vector bundle). (iv)  We have an open condition (ND) on nondegeneracy of the inner product we've built on that vector bundle.
}

Note that $\al'$ is given by the matrix
$$ -T^{-1}_{U,0}
\begin{pmatrix}
  0 & 1  & 0 & \hdots &       0 &  0 \\
  0 & 0 &  1 & \hdots &       0 &  0 \\
\vdots & \vdots & \vdots & \ddots & \vdots & \vdots \\
  0 & 0 &  0 & \hdots &       1 &  0 \\
  0 & 0 &  0 & \hdots &       0 &  1 \\
 T_{U,2d} & T_{U,2d-1} & T_{U,2d-2} & \hdots & T_{U,2} & T_{U,1} 
  \end{pmatrix}
$$

\bpf
We have shown how to get from $X(d)$ to the above data.  We now do the reverse.
We recover $A$ as $A'$.  We recover $\alpha$ as $\alpha'$.  \epf


\tpoint{Proposition} {\em The open condition (iii) on
  $j$ and $\alpha$  is vacuous.}

I separated this from the main theorem because I fear I am making
a mistake.  But it looks to me like we are describing a projective
morphism from $X(d)$ to an affine space parametrizing the $T_{U,i}$'s.
Also, Jim (when meeting in Fort Collins) agreed (for reasons I didn't understand)
that this condition will be automatic.

\bpf
The open condition is that $\ker(\al -x \Id) \cap \ker(j) =0$
for all $x \in \C$.  Here we are interpreting $\al$ as a map $A \rightarrow A$,
and $j$ as a map $A \rightarrow U$.

Suppose $(u_0, \dots, u_{2d-1}) \in \ker(\al -x \Id) \cap \ker(j)$.
Then $u_0=0$ (the $\ker(j)$ condition).

$${\al-x\Id}: (u_0, u_1, \dots, u_{2d-2}, u_{2d-1}) \mapsto$$
$$ \quad \quad \quad
 (u_1-xu_0, u_2-xu_1, \dots, u_{2d-1} - x u_{2d-2},
 -T^{-1}_{U,0} T_{U,1} u_{2d-1}  - \cdots  -T^{-1}_{U,0} T_{U,2d} u_0 -xu_{2d-1})$$

 I think this is automatic!  Solving successively, we get $u_1=0$, then $u_2=0$, and so forth.

 \epf

\tpoint{Proposition} {\em The condition (iv) is vacuous.}

\bpf  The locus where the form is degenerate should be interpreted as the vanishing of a section of a particular (determinant) line bundle.  But this line bundle is the trivial bundle, and the section is nonzero at $p_\infty$. \epf

We now write Theorem~\ref{t:preliminaryform} in its new form.

\tpoint{Theorem}  \label{t:nextform}{\em Recall that we given $d$, $U$, and $T_U: U \rightarrow U^\vee$ (invertible, signed).
  $X(d)$ is paramatrized by precisely the following information.
  We need $T_{U,1}$, \dots, $T_{U,2d}: U \rightarrow U^\vee$ with $T_{U,i}^\vee = - T_{U,i}$ (and define $T_{U,0}=T_U$). Then $X(d)$ consists of the space parametrizing half-dimensional subspaces $\boxed{A'}$ of $U^{\oplus 2d}$ such that (i)
  $A'$ is ``maximal isotropic with respect to the $T$-matrix'' 
 (see Corollary~\ref{c:second}), such that furthermore
(ii)  under the linear map $\al' : U^{2d} \rightarrow U^{2d}$ defined by  $$\boxed{\al'}: (u_0, u_1, \dots, u_{2d-2}, u_{2d-1}) \mapsto
 (u_1, u_2, \dots, u_{2d-1},
 -T^{-1}_{U,0} T_{U,1} u_{2d-1}  - \cdots  -T^{-1}_{U,0} T_{U,2d} u_0 ),$$
 i.e., given by the matrix 
\begin{equation}\label{eq:shift}
\begin{pmatrix}
  0 & 1  & 0 & \hdots &       0 &  0 \\
  0 & 0 &  1 & \hdots &       0 &  0 \\
\vdots & \vdots & \vdots & \ddots & \vdots & \vdots \\
  0 & 0 &  0 & \hdots &       1 &  0 \\
  0 & 0 &  0 & \hdots &       0 &  1 \\
-T^{-1}_{U,0} T_{U,2d} & -T^{-1}_{U,0}T_{U,2d-1} & -T^{-1}_{U,0}T_{U,2d-2} & \hdots & -T^{-1}_{U,0}T_{U,2} & -T^{-1}_{U,0}T_{U,1} 
  \end{pmatrix},
\end{equation}
 $A'$ maps to $A'$.  
}

We will clean it up further below.

 \bpoint{Affine Grassmannian}
 The fiber over $T_{U,i}=0$ is literally $N$th truncation of the symplectic affine Grassmannian.

\bpoint{Aside:  Torus action}

The space has a torus action, which we can presumably interpret in terms
of actions only on the Zariski-lifting sections, although I haven't checked (yet).

The action is as follows.  $T_{U,i} \mapsto t^i T_{U,i}$.
For the half-dimensional subspaces,
we map $\tau: (u_0, \dots, u_{2d-1}) \mapsto (t^0 u_0, \dots, t^{2d-1} u_{2d-1})$.

We verify that (i) continues to hold, by expanding 
$$
\begin{pmatrix}
  u_0 & t u_1 & \cdots & t^{2d-1} u_{2d-1} \end{pmatrix}
 \begin{pmatrix}
t^{2d-1} T_{U,2d-1} & t^{2d-2}T_{U,2d-2} &  t^{2d-3} T_{U,2d-3} &  \hdots & t T_{U,1} & T_{U,0} \\
t^{2d-2}  T_{U,2d-2} &  t^{2d-3}T_{U,2d-3} & t^{2d-4}T_{U,2d-4} &  \hdots & T_{U,0} & 0 \\
   \vdots  & \vdots  &   \vdots  & \ddots & \vdots & \vdots \\
  t T_{U,1} & T_{U,0} & 0 & \hdots & 0 & 0 \\
   T_{U,0} & 0 & 0 & \hdots & 0 & 0 
  \end{pmatrix}
\begin{pmatrix}
  u'_0 \\ t u'_1 \\ \cdots \\ t^{2d-1} u'_{2d-1} \end{pmatrix}
$$
When we expand this out, by inspecting \eqref{eq:second}, we see that we get $t^{2d-1}$
times what we had before, so we still get $0$.

We see that (ii) holds too; put informally,  $\al' \circ \tau = t \tau \circ \al$.

\epoint{Limit of the torus action} Sending $t \rightarrow 0$ the
resulting points in the closed condition
seem to be the symplectic affine Grassmannian.
More precisely:  if we take the limits of conditions (i) and (ii) (the closed conditions),
we describe the symplectic affine Grassmannian.  Caution:  we haven't shown that the flat limit of this family of varieties (satisfying (i) and (ii)) is the symplectic affine Grassmannian; the actual limit might be smaller.

\bpoint{Dimension check}
I'm expecting to see $\dim X(d) = (\dim A) (\dim U) = (2dn)(2n) = 4dn^2$, computed in another way.


From \eqref{eq:dimsag} the truncated symplectic affine Grassmannian
is, I think, $d(2n-1)$.  This should be a  family over the space
of choices of $T_{U,i}$ ($i=1, \dots, 2d$), with generic fiber dimension
at least that of the fiber over zero.
The dimension of choice of each $T_{U,i}$ is, I think, $(2n)(2n+1)/2$; this is something
I find confusing (and we get the {\em same} answer in the orthogonal case).
This underlying affine
space then  has dimension $(2d)(2n+1)n = 4dn^2+2dn$.  Thus the map from $X(d)$ to this affine space is not surjective.  The fibers over zero is 
 the truncated symplectic affine
 Grassmannian, so the fiber over $0$ is of dimension $2dn-d$.

(I would expect that the only global functions on $X(d)$ would be those coming from the $T_{U,i}$.)

\bpoint{Example $d=1$, $n=1$}

Even this case is complicated.  $\dim X(d)$ is supposed to be $4$,
mapped to $\A^6$ (parametrizing $T_{U,1}$ and $T_{U,2}$). The fiber
over $0$ is the SAG, which is $1$-dimensional.
 

\bpoint{Behavior under increase of  $d$ and $n$}

When $d$ increases, we are keeping $U$, but increasing $A$ by $2n=\dim U$.
we are multiplying the sections by $x_0$ (so this involves the choice of a
second point in our genus $0$ curve).  We get a map $\boxed{A_d} \rightarrow \boxed{A_{d+1}}$,

Here is how to increase $d+1$.
$d'=d+1$.  $T'_{U,2d'-1}=T'_{U,2d'}=0$, and $T'_{U,i}= T_{U,i}$ otherwise (if $0 \leq i \leq 2d$).

To get the corresponding $A'$ from $A$, as a subset of $U^\oplus{2d'}$.
Start with your subset of $U^\oplus{2d'}$.  Add $0$ to the front, and $U$ to the end.

$X(d) \rightarrow X(d+1)$ is of course increasingly connected, as can be seen from its incarnation as an open embedding.

Here is how to increase $n$ by $1$.  You increase $U$ by a 2-dimensional vector space (with form), call it $U_1$, so $U_{n+1} = U_{n} \oplus U_1$.   Given $A_n \subset U_n^{2d}$, we get
$A_{n+1} \subset U_n^{2d} \oplus U_1^{2d}$ as $(A_n,0) \oplus (0, 0^{\oplus d} \oplus U_1^{\oplus d})$.

It is not yet clear why $X_n(d) \rightarrow X_{n+1}(d)$ is increasingly connected; I've not thought it through.

\bpoint{Cleaning up  Theorem~\ref{t:nextform} further}

We can do a symplectic Gramm-Schmidt change of basis to make the $T$-matrix antidiagonal, and clean out the non-$T_0$-terms.  

Let's find the change of basis $\boxed{P}$. We will need to invert 2.
Let $M$ be the block matrix of \eqref{eq:Tmatrix} (the ``$T$-matrix''), and let
$M_0$ be the block matrix that is the same but only with the antidiagonal entries (the ``$T_0$-matrix'' perhaps).
I will tell you the matrix $g$ such $P^T M P =M_0$.  $P$ will be a lower-triangular matrix, where
each entry $\ell$ below the diagonal will be called $P_{\ell}$, so $A_0=1$.  Here is the $d=2$ case
as an example.
$$
\begin{pmatrix}
  I & A_1^T & A_2^T & A_3^T \\
  0 &  I & A_1^T & A_2^T  \\
  0 &  0 &  I & A_1^T  \\
  0 &  0 &  0 &  I 
  \end{pmatrix}
  \begin{pmatrix}
    T_3 & T_2 & T_1 & T_0 \\
    T_2 & T_1 & T_0 & 0\\
    T_1 & T_0 & 0  & 0 \\
 T_0 & 0  & 0 & 0\\
  \end{pmatrix}
  \begin{pmatrix}
     I & 0 & 0 & 0 \\
    A_1 &      I & 0 & 0 \\
A_2 &     A_1 &      I & 0 \\
A_3 & A_2 &     A_1 &      I 
  \end{pmatrix}
$$
When you expand this out, each entry  $\ell$ steps above the diagonal
is
$$
\sum_{i+j+k=\ell} A_i^T T_k A_j
$$
The sum has $\binom \ell 2$ terms.
Note that $A_i^T T_k A_j + A_j^T T_k A_i$ is skew (equal to the negative of its transpose).
Hence recursively in $\ell$, we get
$$
A_\ell^T T_0 + T_0 A_\ell = - T_\ell  - \sum^\sim_{i+j+k=\ell} A_i^T T_k A_j
$$
where the sum omits the three obvious terms.
We can get a choice-free solution by taking both terms on the left to be equal:
$$
A_\ell \coloneq - \frac 1 2 T_0^{-1} \left(  \sum_{i+j+k=\ell; i,j<\ell} A_i^T T_k A_j \right).
$$
We note that our $A_\ell$ satisfy $T_0 A_\ell T_0^{-1} = A_\ell^T$, i.e.,  $A_\ell$ is
a  self–adjoint endomorphisms with respect to the bilinear form defined by $T_0$.  I think they are
the opposite of the Lie algebra of the symplectic group.   So this really is a canonical choice.

Here are the first values.

\[
A_1 \;=\; -\tfrac12\,T_0^{-1}\,T_1
\]


\[
A_2 =
\frac 3 8 T_0^{-1}  T_1  T_0^{-1} T_1
-  \frac 1 2 T_0^{-1}  T_2.
\]

\[
A_3 \;=\;
-\tfrac18\,T_0^{-1}\,T_1\,T_0^{-1}\,T_1\,T_0^{-1}\,T_1
\;+\;\tfrac14\,T_0^{-1}\bigl(T_1\,T_0^{-1}\,T_2 \;+\; T_2\,T_0^{-1}\,T_1\bigr)
\;-\;\tfrac12\,T_0^{-1}\,T_3.
\]


\[
\begin{aligned}
A_4 &= -\frac12\,T_0^{-1}\Bigl(\,
T_4
-\tfrac12\bigl(T_3\,T_0^{-1}T_1 \;+\; T_1\,T_0^{-1}T_3\bigr)
-\,T_2\,T_0^{-1}T_2
+\tfrac14\,T_1\,T_0^{-1}T_2\,T_0^{-1}T_1\\
&\quad
+\tfrac38\,T_2\,T_0^{-1}T_1\,T_0^{-1}T_1
+\tfrac38\,T_1\,T_0^{-1}T_1\,T_0^{-1}T_2
-\tfrac18\,T_1\,T_0^{-1}T_1\,T_0^{-1}T_1\,T_0^{-1}T_1\\
&\quad
-\tfrac12\bigl(T_1\,T_0^{-1}T_3 \;+\; T_3\,T_0^{-1}T_1\bigr)
\Bigr).
\end{aligned}
\]

I bet I can figure out a formula for all the coefficients.

\epoint{In the new basis, understanding the shift}

\label{s:newbasisshift}We now consider the shift matrix \eqref{eq:shift}, in the new basis.
We compute $P N P^{-1}$.
$$
  \begin{pmatrix}
     I & 0 & 0 & 0 \\
    A_1 &      I & 0 & 0 \\
A_2 &     A_1 &      I & 0 \\
A_3 & A_2 &     A_1 &      I 
  \end{pmatrix}
  \begin{pmatrix}
  0 & 1  & 0 & \hdots &       0 &  0 \\
  0 & 0 &  1 & \hdots &       0 &  0 \\
\vdots & \vdots & \vdots & \ddots & \vdots & \vdots \\
  0 & 0 &  0 & \hdots &       1 &  0 \\
  0 & 0 &  0 & \hdots &       0 &  1 \\
-T^{-1}_{U,0} T_{U,2d} & -T^{-1}_{U,0}T_{U,2d-1} & -T^{-1}_{U,0}T_{U,2d-2} & \hdots & -T^{-1}_{U,0}T_{U,2} & -T^{-1}_{U,0}T_{U,1} 
  \end{pmatrix}
  \begin{pmatrix}
     I & 0 & 0 & 0 \\
    B_1 &      I & 0 & 0 \\
B_2 &     B_1 &      I & 0 \\
B_3 & B_2 &     B_1 &      I 
  \end{pmatrix}
  $$
  
  Here the matrix with the $B$'s is the inverse of the matrix with the $A$'s, so $A_1+B_1=0$, $A_2+A_1 B_1 + B_2 =0$, $A_3 + A_2 B_1 + A_1 B_2  + B_3=0$, etc.
  The first two multiplied together give:
  $$
  \begin{pmatrix}
    0 & I & 0 & 0 \\
    0 & A_1 & I & 0 \\
    0 & A_2 & A_1 & I \\
    -T_0^{-1} T_4 & A_3 - T_0^{-1} T_3 & A_2 - T_0^{-1} T_2 & A_1 - T_0^{-1} T_1 
  \end{pmatrix}
  $$
  Then when multiplying it out it is easy to see the first three rows, but the fourth is a mess:
$$
\begin{pmatrix}
  -A_1 & I & 0 & 0 \\
  -A_2 & 0 & I & 0 \\
  - A_3 & 0 & 0 & I \\
  ? & ? & ? & ?
\end{pmatrix}
$$

But in any case we are now considering maximal isotropic subspaces in $U^\oplus{2d}$ (with the usual form) along with generally chosen $A_1$, $A_2$, $A_3$, ..., $A_{2d-1}$, $T_{2d}$, subject to the condition that $A$ is closed under the transformation:
$$
(u_0, u_1, u_2, ..., u_{2d-1}) \mapsto   (u_1 -A_1 u_0, u_2 - A_2 u_0, ..., u_{2d-1} - A_{2d-1} u_0, ???)$$

I have no fucking idea why this is smooth from this point of view, let alone why there is a map to $LG(U)$, or why this
map is highly connected.

\epoint{What next} Now to understand this space, we conder $LG(U^{\oplus 2d})$, with this $T_0$-pairing, parametrizing
maximal isotropic subspaces $A \subset U^{\oplus 2d}$.
Over this space, we have the tautological sequence $0 \rightarrow A \rightarrow U^{\oplus 2d} \rightarrow Q \rightarrow 0$
of vector bundles.
Let's find the $T_1$, \dots, $T_{2d}$ so that (ii) holds.    We have a trivial vector bundle $T$
parametrizing canddiate $T_1$, \dots, $T_{2d}$ (roughly speaking, each elements of $\wedge^2 U$)
which map to $\Hom( A,Q)$ --- basically, they give a map from $A$ to $U$.
We are consider $\ker( T, \Hom(A,Q))$.

\bpoint{Daniel Litt's gambit}

Daniel Litt points out that there is good reason for thinking that the case $d=1$ may suffice.  So here is the above discussion, in the special case $d=1$.  From \ref{s:newbasisshift}:

We compute $P N P^{-1}$.
$$
  \begin{pmatrix}
     I & 0\\
    A_1 &      I   \end{pmatrix}
  \begin{pmatrix}
  0 & 1 \\
 -T^{-1}_{U,0}T_{U,2} & -T^{-1}_{U,0}T_{U,1} 
  \end{pmatrix}
  \begin{pmatrix}
     I & 0 \\
    -A_1 &      I   \end{pmatrix} =
  \begin{pmatrix}
    0 & I \\
A_2 - T_0^{-1} T_2 & A_1 - T_0^{-1} T_1 
  \end{pmatrix}
  \begin{pmatrix}
     I & 0 \\
    -A_1 &      I   \end{pmatrix}  
  $$
  $$
  = \begin{pmatrix}
    -A_1 & I \\
A_2 - T_0^{-1} T_2 - A_1^2 + T_0^{-1} T_1 A_1    & A_1 - T_0^{-1} T_1
  \end{pmatrix}
  $$

  For convenience let $S_i = T_0^{-1} T_i$.
  Then $A_1 = - \frac 1 2 S_1$ and $A_2 = \frac 3 8 S_1^2 - \frac 1 2 S_2$.
  Then the transition matrix is:
 $$
 \begin{pmatrix}
    - \frac 1 2 S_1  & I \\ 
    \frac 3 8 S_1^2 - \frac 1 2 S_2 - S_2 + \frac 1 4 S_1^2 - \frac 1 2 S_1^2 & - \frac 1 2 S_1 - S_1 
 \end{pmatrix}
 = 
 \begin{pmatrix}
    - \frac 1 2 S_1  & I \\ 
    \frac 1 8 S_1^2 - \frac 3 2 S_2 &  - \frac 3 2 S_1
 \end{pmatrix}
 $$
 So the space is an isotropic subspace of $A \subset U_0 \oplus U_1$ along with an endormorphism
 $$\alpha:  (u_0, u_1) \mapsto (u_1 -\frac 1 2 S_1 u_0, -\frac 3 2 S_2 u_0 + \frac 1 8 S_1^2 u_0 - \frac 3 2 S_1 u_1).
$$
 
\section{To do next}


Is $X_n(d) \rightarrow X_{n+1}(d)$ increasingly connected?

\bpoint{Describe the map to the Lagrangian Grassmannian}

Question: Is there a variation of the definition of the Nth truncation of the symplectic affine Grassmannian that yields a bigger subvariety of the Nth truncation of the Lagrangian Sato Grassmannian that is actually smooth?
Gerd Faltings, Algebraic loop groups and moduli spaces of bundles. J. Eur. Math. Soc. 5 (2003), no. 1, pp. 41–68.
Ulrich Gortz, On the flatness of local models for the symplectic group, Adv. Math. 176 (2003), 89–115. look around Prop 5.1.

}  %end parskip at the start of the file


\begin{thebibliography}{[HPLqjm]}


\bibitem[MOV]{mov} A. Malkin, V. Ostrik, and M. Vybornov, {\em  The minimal degeneration singularities in the affine Grassmannians}, Duke Math. J., 126(2):233–249,
2005.

\bibitem[Na]{nadler} David Nadler, {\em Matsuki correspondence for the affine Grassmannian}, Duke Math. J. 124 (2004), no.\ 3,
421–457.

\bibitem[PS]{ps} 
Andrew Pressley and Graeme Segal, Loop groups, Oxford Mathematical Monographs, The Clarendon Press, Oxford University Press, New York, 1986. 

\bibitem[Z]{zhu} Xinwen Zhu, {\em An introduction to affine Grassmannians and the geometric Satake equivalence}, IAS/Park City Mathematics Series (expanded lecture notes from the 2015 PCMI Summer School), April 4, 2016.  \verb+https://arxiv.org/abs/1603.05593+
\end{thebibliography}

\end{document}
